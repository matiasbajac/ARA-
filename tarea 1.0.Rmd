---
title: "Tarea 1"
subtitle: "Fundamentos de Análisis Bayesiano y Análisis de Riesgos
Adversarios"
author: "Gabriel Bermudez (C.I. 5.242.985-8), Matias Bajac (C.I. 5.448.679-3)"
date: '2025-06-12'
output:
  pdf_document: default
  html_document: default
header-includes:
  - \usepackage{cancel}
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Consider a sample $\underline{X} = (X_{1}, X_{2}, \dots, X_{n})$ from a Poisson distribution $\mathcal{P}(\lambda)$, with density $f(x) = \frac{\lambda^{x}}{x!}e^{-\lambda}$ with $x \in \mathbb{N}$ and $\lambda>0$.

---

1) Write the likelihood based on the sample $\underline{X}$. 

$$
\begin{aligned}
f(x_1,x_2...,x_n | \lambda) & = f(\vec{x} | \lambda) = \prod_{i=1}^{n} \frac{\lambda^{x_i}e^{-\lambda}}{x!}
f(\vec{x}/ \lambda) = \frac{\lambda^{x_1} e^{-\lambda}}{x_1!}\frac{\lambda^{x_2} e^{-\lambda}}{x_2!} \cdots \frac{\lambda^{x_n}e^{\lambda}}{x!} = \\ \\
 & = \frac{[\lambda^{x_1} \lambda^{x_2}... \lambda^{xn}][e^{-\lambda} e^{-\lambda}...e^{-\lambda}]}{x_n!} =\frac{\lambda^{\sum_{i=1}^nx_i}e^{-\lambda n}}{\prod_{i=1}^nx_i!}
\end{aligned}
$$

---

2) Compute the Maximum Likelihood Estimator (MLE) $\hat{\lambda}_{MLE}$ of $\lambda$ given $\underline{X}$.
$$
\begin{aligned}
 &  \ell(\lambda \mid \underline{X}) = \sum X_{i}\ln(\lambda) - \lambda n \\ \\
 &  \frac{ \partial\ \ell(\lambda \mid \underline{X}) }{ \partial \lambda } = \frac{\sum X_{i}}{\lambda} -  n = 0 \iff \lambda = \frac{\sum{X_{i}}}{n} \\ \\
&  \implies \boxed{\hat{\lambda}_{MLE} = \bar{X}}
\end{aligned}
$$

---

3) Choose (and justify your choice) the functional form of the prior distribution on $\lambda$ considering one of the distributions presented in class, i.e Gaussian (Normal), Gamma,Exponential, Beta,Uniform

Debido a que el soporte de  la distribución Poisson es $\lambda > 0$ , es razonable pensar que una priori conjugada para $\lambda$ podria ser una priori  $\lambda \sim Gamma (\alpha,\beta)$ con soporte $\alpha >0 \ y\ \beta>0$.

---

4) Compute the posterior distribution of $\lambda$ and a Bayesian estimator $\hat{\lambda}_{PO}$

$$
\begin{aligned}
& f(\lambda/x_1,x_2,...,x_n) \propto f(\lambda)f(\vec {x} / \lambda) \propto\lambda^{\alpha -1}e^{-\beta \lambda} \lambda^{\sum xi}e^{-\lambda n} \propto \\ 
& e^{-\lambda n -\beta \lambda} \lambda^{\alpha-1 + \sum_{i=1}^n x_i} \propto e^{\lambda(n + \beta)} \lambda^{\alpha-1 +\sum_{i=1}^nx_i}\\
& \lambda / x_1,..,x_n \sim Gamma(\alpha,\sum_{i=1}^nx_i,n + \beta)
\end{aligned}
$$
Bajo pérdida cuadratica, el estimador bayesiano es la media a posteriori

$$
\begin{aligned}
& \hat{\lambda}_{PO} = E(\lambda / \vec{X}) = \frac{\alpha + \sum_{i=1}^nx_i}{\beta + n}
\end{aligned}
$$

---

5) (Optional) Comment about what happens too $\hat{\lambda}_{PO}$ when (like done in class)

- letting the prior variance going to 0

- letting the prior variance going to $\infty$

- letting the sample size going to $\infty$


$$
\begin{aligned}
media \ a \ priori \  \hat{\lambda}  = \frac{\alpha k + \sum_{i=1}^n x_i}{\beta_k +n}
\end{aligned}
$$


$$
\begin{aligned}
& k \rightarrow 0 \ \text{varianza a priori} \rightarrow \infty \rightarrow \hat{\lambda} \rightarrow \sum_{i=1}^n \frac{x_i}{n} = \bar{x} \sim \text{EMV} \\
& k \rightarrow \infty \ \text{varianza a priori} \rightarrow 0 \rightarrow \hat{\lambda} \rightarrow  \frac{\alpha}{\beta} \rightarrow \text{media a priori} \\
& n \rightarrow \infty \rightarrow \hat{\lambda} \sim \frac{\alpha + \cancel{n} \bar{x}}{\beta + \cancel{n}} \rightarrow \bar{x} \sim \text{EMV}
\end{aligned}
$$

---

6) Compute the posterior predictive distribution for a next observation $X_{n+1}$ given the sample X

$$
\begin{aligned}
& fX_{n +1}(X_{n+1}/X) = \int_{0}^{\infty} \underbrace{\frac{\lambda^{ x_n +1}e^{-\lambda}}{x_{n+1}!}}_{f(x_{n+1/\lambda})} \underbrace{\frac{(n + \beta)}{\Gamma{\alpha+ \sum x_i}}^{\alpha +\sum x_i}  \lambda^{\alpha +\sum x_i -1 }e^{-\lambda(n + \beta)}}_{f(\lambda/X=x)}  d\lambda = \\
& \frac{(n+\beta)^{\alpha +\sum x_i}}{\Gamma{\alpha +\sum x_i}}\frac{1}{x_{n+1!}} \int_{0}^{\infty} \lambda^{ x_{n+1} -1 + \alpha +\sum x_i} e^{-\lambda(1 + \beta + n)} d \lambda  \\
\end{aligned}
$$

---

7) Describe, in your words, why MLE and posterior mean are sound choices as estimators of a parameter 

El estimador máximo verosimil da la media muestral el cual parece ser una buena eleccion en inferencia clásica   ya que   usa unicamente la información de los datos,  dando como resultado un estadistico de resumen   mientras tanto  en un   enfoque bayesiano,  la media a posteriori (pérdida cuadratica) incorpora la información a priori además de la verosimilitud de los datos.

---

9) (Optional) You will do the exercise considering i.i.d. Poisson distributions but you should comment about such choice, i.e. on the assumptions that we are making considering Poisson and considering i.i.d.. Are they completely justified or not? If not, what are the critical aspects?

Considerando que la distribución Poisson está definida solo para valores positivos y discretos, esto se alinea con los datos que tenemos: Claramente no puede haber una cantidad negativa de muertos ni una fraccion de ellos.
Además, la distribución Poisson es asimétrica hacia la derecha, más notoriamente si $\lambda$ es *chico*, lo que significa que sobre los valores bajos de $X$ se concentra una mayor masa de probabilidad, cosa que también tiene sentido con la situación que se está modelando.

---

10) Compute the MLE of $\lambda$.

En el ejercicio número 2 se llegó a la conclusión que si los datos siguen una distribución de Poisson, entonces el MLE de $\lambda$ es igual a la **media muestra**.
En este caso:
$$
\hat{\lambda}_{MLE} = \bar{X} = 10
$$

---

11) Based on your experience in your home country, assign the parameters to the prior distribution on $\lambda$. As in class, it might be useful to think what is the ”physical meaning” of $\lambda$ and then think of its possible value, to be considered as a mean, and a trust on such assessment, which could be considered as a variance.

Teniendo en cuenta que:
- En 2024 se registraron casi 15 muertes en accidentes automovilísticos por 100,000 habitantes en Uruguay, y 
- Que esperamos que este año sea mejor en este sentido, 

Vamos a querer que la prior mean de $\pi(\lambda)$ sea 14. Recordando que elegimos como distribución a priori una Gamma ($\mathcal{G}(\alpha,\beta)$), podemos plantear la siguiente igualdad:
$$
\begin{aligned}
\mathbb{E}\left[ \pi(\lambda) \right] = \frac{\alpha}{\beta} & = 14\\ \\
\alpha &= 14\beta \\ \\
\implies (\alpha, \beta) & = (14,1)
\end{aligned}
$$
Lo que nos deja con una confianza (Trust) en nuestra estimación de:
$$
\mathbb{V}(\pi(\lambda)) = \frac{\alpha}{\beta^{2}} = 14 \implies \text{sd (`Trust')} = \sqrt{ 14 } \simeq 3.74
$$

---

12) Compute the posterior mean of $\lambda$ using your elicited prior (elicitation
= process leading to the choice of a prior)

En nuestro caso, como $\alpha=14$, $\beta=1$, $\sum X_{i}=100$ y $n=10$:

$$
\begin{aligned}
 & \implies\pi(\lambda \mid\underline{X}) \sim \mathcal{G}\Bigg( \underbrace{ \sum X_{i} }_{ 100 } + \underbrace{ \alpha }_{ 14 },\ \underbrace{ n }_{ 10 } + \underbrace{ \beta }_{ 1 } \Bigg) = \mathcal{G}\left( 114, 11 \right)  \\ \\
 & \implies \boxed{\mathbb{E}\left[ \pi(\lambda \mid\underline{X}) \right] =\frac{114}{11}= 10.36}
\end{aligned}
$$

---

13) (Optional) Try some different values of the parameters and comment what happens to the posterior mean.

Si $\displaystyle{(\alpha, \beta) = (42, 3) \implies \pi(\lambda \mid\underline{X})\sim \mathcal{G}\left( \sum X_{i}+42, n+3 \right) = \mathcal{G}\left( 142, 13 \right)}$
Por lo tanto, $\mathbb{E}\left[ \pi(\lambda \mid\underline{X}) \right] = \frac{142}{13}=10.92$

Al aumentar los parámetros de la $\mathcal{G}(\alpha, \beta)$,  la esperanza el parámetro $\lambda$ también aumenta, lo que se refleja en una estimación más grande.

---

15 ) (Optional) For those who know R, look for (and use!) the very simple commands which allow you to build a 95% credible interval for $\lambda$, using the previous data and your prior distribution.

$$
\begin{aligned}
 & \pi(\lambda) \sim \mathcal{G}\left( \alpha, \beta \right) \\ \\
\to\ & \mathbb{E}[\pi(\lambda)] = \frac{\alpha}{\beta} = 14\\
\to\ & \mathbb{V}[\pi(\lambda)] = \frac{\alpha}{\beta^{2}} = 7 \\ \\
\implies\  & Z = \frac{\lambda-14}{\sqrt{ 7 }} \sim N(0,1) \\ \\
 & P\left( -1.96 < \frac{\lambda-14}{\sqrt{ 7 }} < 1.96 \right) = 0.95 \\\\
\implies  & \boxed{\left( 14 - 1.96\sqrt{ 7 },\ 14 + 1.96\sqrt{ 14 } \right)}
\end{aligned}
$$
Es el intervalo de credibilidad al 95% para $\lambda$

```{r}
#| echo: true

ICi = 14 - 1.96*sqrt(7)
ICd = 14 + 1.96*sqrt(7)

paste("[ ", round(ICi), ", ", round(ICd), " ]", sep = "")
``` 


